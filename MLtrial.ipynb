{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try different test and train ration 10 to 50 percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making arrays of N, Z, A and y the binding Energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.genfromtxt('expthediff.dat',usecols=0) #Number of neutrons\n",
    "Z = np.genfromtxt('expthediff.dat',usecols=1) #Number of protons\n",
    "A = N+Z # Total number of Nucleons\n",
    "# Difference between the experimental binding energy and the Liquid drop model\n",
    "y = np.genfromtxt('expthediff.dat',usecols=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Plots of N, Z, A to Binding Energies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binding Energies against Number of Protons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Z,y,'o',markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binding Energies against Number of Neutrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(N,y,'o',markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binding Energies against Number of Atomic Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(A,y,'o',markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N vs Z with Binding Energies indicated in color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = np.int(np.ceil(max(-np.min(y),np.max(y))))\n",
    "fig=plt.figure(figsize=(18, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "sc = plt.scatter(N,Z,c=y,cmap='PiYG',vmin=-ext,vmax=ext,s=10)\n",
    "plt.colorbar(sc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting test data set into train and test est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.transpose(np.stack((N,Z)))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train) # This sets the shifting and scaling so the training features have mean zero and variance 1\n",
    "\n",
    "Xs_train = scaler.transform(X_train) # Scaling the training features\n",
    "\n",
    "Xs_test = scaler.transform(X_test) #Using the SAME scaling on the test features in order to get the correct score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making rf the Random Forest object\n",
    "\n",
    "Using Scaling innitially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model \n",
    "rf = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
    "rf.fit(Xs_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=rf.predict(Xs_train)\n",
    "errors = predictions-y_train\n",
    "print('Without Magic Numbers as Features')\n",
    "print('Mean Absolute Error for train data:', round(np.mean(errors), 5), )\n",
    "print('Median Absolute Error for train data:', round(np.median(errors), 5), '\\n')\n",
    "Etrain1=np.mean(errors)\n",
    "Emedtrain1=np.median(errors)\n",
    "\n",
    "predictions=rf.predict(Xs_test)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error for test data:', round(np.mean(errors), 5) )\n",
    "print('Median Absolute Error for test data:', round(np.median(errors), 5), '\\n\\n')\n",
    "Etest1=np.mean(errors)\n",
    "Emedtest1=np.median(errors)\n",
    "\n",
    "\n",
    "\n",
    "#the coefficient of determination R^2 of the prediction\n",
    "# The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum()\n",
    "#and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum().     \n",
    "trainscore1=rf.score(Xs_train, y_train)\n",
    "testscore1=rf.score(Xs_test, y_test)\n",
    "\n",
    "print('The coefficient of determination for training: ', round(trainscore1,5))\n",
    "print('The coefficient of determination for testing: ', round(testscore1,5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance for N and Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramater Weight \n",
    "print('N:', rf.feature_importances_[0])\n",
    "print('Z:', rf.feature_importances_[1],     '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = scaler.transform(X)\n",
    "pred_all = rf.predict(Xs) \n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(18, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "sc = plt.scatter(np.transpose(X)[0],np.transpose(X)[1],c=pred_all,cmap='PiYG',vmin=-ext,vmax=ext,s=10)\n",
    "plt.colorbar(sc)\n",
    "plt.show()\n",
    "\n",
    "err_all=y-pred_all\n",
    "ext1 = np.int(np.ceil(max(-np.min(err_all),np.max(err_all))))\n",
    "fig=plt.figure(figsize=(18, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "sc = plt.scatter(np.transpose(X)[0],np.transpose(X)[1],c=err_all,cmap='PiYG',vmin=-ext1,vmax=ext1,s=10)\n",
    "plt.colorbar(sc)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(N+Z,y,'o',markersize=1,label='Original')\n",
    "plt.plot(np.transpose(X)[0]+np.transpose(X)[1],pred_all,'o',markersize=1,label='Trained')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.transpose(X)[0]+np.transpose(X)[1],err_all,'o',markersize=1,label='Error')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding magic numbers as a feature\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.transpose(np.stack((N,Z,N+Z,N-Z,np.exp(-(20-N)**2/20.),np.exp(-(20-Z)**2/20.),np.exp(-(28-N)**2/20.),np.exp(-(28-Z)**2/20.),np.exp(-(50-N)**2/20.),np.exp(-(50-Z)**2/20.),np.exp(-(80-N)**2/20.),np.exp(-(80-Z)**2/20.),np.exp(-(126-N)**2/20.),np.exp(-(126-Z)**2/20.))))\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train) # This sets the shifting and scaling so the training features have mean zero and variance 1\n",
    "\n",
    "Xs_train = scaler.transform(X_train) # Scaling the training features\n",
    "\n",
    "Xs_test = scaler.transform(X_test) #Using the SAME scaling on the test features in order to get the correct score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model \n",
    "rf.fit(Xs_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Without magic numbers as a feature:')\n",
    "print('Mean Absolute Error for Xs_train data:', Etrain1)\n",
    "print('Median Absolute Error for Xs_train data:', Emedtrain1, '\\n')\n",
    "\n",
    "print('Mean Absolute Error for Xs_test data:', Etest1)\n",
    "print('Median Absolute Error for Xs_test data:', Emedtest1, '\\n')\n",
    "\n",
    "print('Mean Error difference between test and train data: ', round(Etest1-Etrain1, 5) )\n",
    "print('Median Error difference  between test and train data: ', round(Emedtest1-Emedtrain1, 5), \"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "predictions=rf.predict(Xs_train)\n",
    "errors = abs(predictions- y_train)\n",
    "Etrain2=np.mean(errors)\n",
    "Emedtrain2=np.median(errors)\n",
    "\n",
    "predictions=rf.predict(Xs_test)\n",
    "errors = abs(predictions - y_test)\n",
    "Etest2=np.mean(errors)\n",
    "Emedtest2=np.median(errors)\n",
    "\n",
    "\n",
    "print('With magic numbers as a feature:')\n",
    "\n",
    "print('Mean Absolute Error for Xs_train data', Etrain2 )\n",
    "print('Median Absolute Error for Xs_train data', Emedtrain2, '\\n')\n",
    "\n",
    "print('Mean Absolute Error for Xs_test data:', Etest2)\n",
    "print('Median Absolute Error for Xs_test data:', Emedtest2, '\\n')\n",
    "\n",
    "print('Mean Error difference between test and train data: ', Etest2-Etrain2)\n",
    "print('Median Error difference between test and train data: ', Emedtest2-Emedtrain2, '\\n\\n\\n')\n",
    "\n",
    "\n",
    "imprtest=Etest2-Etest1\n",
    "imprtrain=Etrain2-Etrain1\n",
    "\n",
    "imprmedtest=Emedtest2-Emedtest1\n",
    "imprmedtrain=Emedtrain2-Emedtrain1\n",
    "\n",
    "\n",
    "print('===================================================')\n",
    "print('difference between the mean train error of with and without added features:', imprtrain)\n",
    "print('difference between the mean test error of with and without added features', imprtest, '\\n')\n",
    "\n",
    "print('difference between the median train error of with and without added features', imprmedtrain)\n",
    "print('difference between the median test error of with and without added features', imprmedtest)\n",
    "print('===================================================', '\\n\\n\\n')\n",
    "\n",
    "trainscore2=rf.score(Xs_train, y_train)\n",
    "testscore2=rf.score(Xs_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Without magic numbers as a feature:')\n",
    "print('The coefficient of determination for training: ', trainscore1)\n",
    "print('The coefficient of determination for testing: ', testscore1)\n",
    "print('score difference: ', trainscore1-testscore1, '\\n')\n",
    "\n",
    "\n",
    "print('With magic numbers as a feature:')\n",
    "print('The coefficient of determination for training: ', trainscore2)\n",
    "print('The coefficient of determination for testing: ', testscore2)\n",
    "print('score difference: ', trainscore2-testscore2, '\\n\\n\\n')\n",
    "\n",
    "imprtestscore=testscore2-testscore1\n",
    "imprtrainscore=trainscore2-trainscore1\n",
    "\n",
    "\n",
    "print('===================================================')\n",
    "print('difference between the train score of with and without added features:', imprtrainscore)\n",
    "print('difference between the test score of with and without added features', imprtestscore)\n",
    "print('===================================================', '\\n\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('N:', rf.feature_importances_[0])\n",
    "print('Z:', rf.feature_importances_[1],     '\\n')\n",
    "\n",
    "print('N+Z:', rf.feature_importances_[2])\n",
    "print('N-Z:', rf.feature_importances_[3],   '\\n')\n",
    "\n",
    "print('20-N:', rf.feature_importances_[4])\n",
    "print('20-Z:', rf.feature_importances_[5],  '\\n')\n",
    "\n",
    "print('28-N:', rf.feature_importances_[6])\n",
    "print('28-Z:', rf.feature_importances_[7],  '\\n')\n",
    "\n",
    "print('50-N:', rf.feature_importances_[8])\n",
    "print('50-Z:', rf.feature_importances_[9],  '\\n')\n",
    "\n",
    "print('80-N:', rf.feature_importances_[10])\n",
    "print('80-Z:', rf.feature_importances_[11], '\\n')\n",
    "\n",
    "print('126-N:', rf.feature_importances_[12])\n",
    "print('126-Z:', rf.feature_importances_[13],'\\n')\n",
    "\n",
    "rf.feature_importances_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Have to refit rf with all of X and y \n",
    "#Unlike with scaling\n",
    "\n",
    "Xs = scaler.transform(X)\n",
    "pred_all = rf.predict(Xs) \n",
    "\n",
    "fig=plt.figure(figsize=(18, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "sc = plt.scatter(np.transpose(X)[0],np.transpose(X)[1],c=pred_all,cmap='PiYG',vmin=-ext,vmax=ext,s=10)\n",
    "plt.colorbar(sc)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "err_all=y-pred_all\n",
    "ext1 = np.int(np.ceil(max(-np.min(err_all),np.max(err_all))))\n",
    "fig=plt.figure(figsize=(18, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "sc = plt.scatter(np.transpose(X)[0],np.transpose(X)[1],c=err_all,cmap='PiYG',vmin=-ext1,vmax=ext1,s=10)\n",
    "plt.colorbar(sc)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(N+Z,y,'o',markersize=3,label='Original')\n",
    "plt.plot(np.transpose(X)[0]+np.transpose(X)[1],pred_all,'o',markersize=3,label='Trained')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#plt.plot(N+Z,y,'o',markersize=3,label='Original')\n",
    "plt.plot(np.transpose(X)[0]+np.transpose(X)[1],err_all,'o',markersize=1,label='Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest without Scaling \n",
    "\n",
    "Innitially without magic Numbers as Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.transpose(np.stack((N,Z)))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model \n",
    "rf.fit(X_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=rf.predict(X_train)\n",
    "errors = abs(predictions-y_train)\n",
    "\n",
    "print('Mean Absolute Error for train data:', round(np.mean(errors), 5), )\n",
    "print('Median Absolute Error for train data:', round(np.median(errors), 5), '\\n')\n",
    "Etrain1=np.mean(errors)\n",
    "Emedtrain1=np.median(errors)\n",
    "\n",
    "predictions=rf.predict(X_test)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error for test data:', round(np.mean(errors), 5) )\n",
    "print('Median Absolute Error for test data:', round(np.median(errors), 5),  '\\n\\n\\n')\n",
    "Etest1=np.mean(errors)\n",
    "Emedtest1=np.median(errors)\n",
    "\n",
    "\n",
    "#the coefficient of determination R^2 of the prediction\n",
    "# The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum()\n",
    "#and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum().     \n",
    "trainscore1=rf.score(X_train, y_train)\n",
    "testscore1=rf.score(X_test, y_test)\n",
    "\n",
    "print('The coefficient of determination for training: ', trainscore1)\n",
    "print('The coefficient of determination for testing: ', testscore1)\n",
    "print('score difference: ', trainscore1-testscore1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance\n",
    "\n",
    "print('N:', rf.feature_importances_[0])\n",
    "print('Z:', rf.feature_importances_[1],     '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_all = rf.predict(X) \n",
    "fig=plt.figure(figsize=(18, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "sc = plt.scatter(np.transpose(X)[0],np.transpose(X)[1],c=pred_all,cmap='PiYG',vmin=-ext,vmax=ext,s=10)\n",
    "plt.colorbar(sc)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "err_all=y-pred_all\n",
    "ext1 = np.int(np.ceil(max(-np.min(err_all),np.max(err_all))))\n",
    "fig=plt.figure(figsize=(18, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "sc = plt.scatter(np.transpose(X)[0],np.transpose(X)[1],c=err_all,cmap='PiYG',vmin=-ext1,vmax=ext1,s=10)\n",
    "plt.colorbar(sc)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(N+Z,y,'o',markersize=3,label='Original')\n",
    "plt.plot(np.transpose(X)[0]+np.transpose(X)[1],pred_all,'o',markersize=3,label='Trained')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.transpose(X)[0]+np.transpose(X)[1],err_all,'o',markersize=1,label='Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding magic numbers as a feature\n",
    "\n",
    "still without scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.transpose(np.stack((N,Z,N+Z,N-Z,np.exp(-(20-N)**2/20.),np.exp(-(20-Z)**2/20.),np.exp(-(28-N)**2/20.),np.exp(-(28-Z)**2/20.),np.exp(-(50-N)**2/20.),np.exp(-(50-Z)**2/20.),np.exp(-(80-N)**2/20.),np.exp(-(80-Z)**2/20.),np.exp(-(126-N)**2/20.),np.exp(-(126-Z)**2/20.))))\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model \n",
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Without magic numbers as a feature:')\n",
    "print('Mean Absolute Error for Xs_train data:', round(Etrain1,5))\n",
    "print('Median Absolute Error for Xs_train data:', round(Emedtrain1, 5), \"\\n\")\n",
    "\n",
    "print('Mean Absolute Error for Xs_test data:', round(Etest1,5))\n",
    "print('Median Absolute Error for Xs_test data:', round(Emedtest1, 5), \"\\n\")\n",
    "\n",
    "print('Mean Error difference between test and train: ', round((Etest1-Etrain1),5) )\n",
    "print('Median Error difference between test and train: ', round( (Emedtest1-Emedtrain1) ,5), \"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "predictions=rf.predict(X_train)\n",
    "errors = abs(predictions- y_train)\n",
    "Etrain2=np.mean(errors)\n",
    "Emedtrain2=np.median(errors)\n",
    "\n",
    "\n",
    "predictions=rf.predict(X_test)\n",
    "errors = abs(predictions - y_test)\n",
    "Etest2=np.mean(errors)\n",
    "Emedtest2=np.median(errors)\n",
    "\n",
    "\n",
    "print('With magic numbers as a feature:')\n",
    "print('Mean Absolute Error for Xs_train data', round(Etrain2, 5) )\n",
    "print('Median Absolute Error for Xs_train data', round(Emedtrain2, 5), '\\n' )\n",
    "\n",
    "\n",
    "print('Mean Absolute Error for Xs_test data:', round(Etest2, 5))\n",
    "print('Median Absolute Error for Xs_test data:', round(Emedtest2, 5), '\\n')\n",
    "\n",
    "print('Mean Error difference between test and train: : ', round((Etest2-Etrain2),5))\n",
    "print('Median Error difference between test and train: : ', round((Emedtest2-Emedtrain2),5),  '\\n\\n\\n')\n",
    "\n",
    "\n",
    "imprtest=Etest2-Etest1\n",
    "imprtrain=Etrain2-Etrain1\n",
    "\n",
    "imprmedtest=Emedtest2-Emedtest1\n",
    "imprmedtrain=Emedtrain2-Emedtrain1\n",
    "\n",
    "print('===================================================')\n",
    "print('Difference between mean train error of with and and without MN features:', round(imprtrain,5))\n",
    "print('Difference between mean test error of with and and without MN features:',  round(imprtest,5 ), '\\n')\n",
    "\n",
    "print('Difference between median train error of with and and without MN features:', round(imprmedtrain,5))\n",
    "print('Difference between median test error of with and and without MN features:',  round(imprmedtest,5 ))\n",
    "print('===================================================', '\\n\\n\\n')\n",
    "\n",
    "trainscore2=rf.score(X_train, y_train)\n",
    "testscore2=rf.score(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Without magic numbers as a feature:')\n",
    "print('The coefficient of determination for training: ', trainscore1)\n",
    "print('The coefficient of determination for testing: ', testscore1)\n",
    "print('score difference: ', trainscore1-testscore1, '\\n')\n",
    "\n",
    "\n",
    "print('With magic numbers as a feature:')\n",
    "print('The coefficient of determination for training: ', trainscore2)\n",
    "print('The coefficient of determination for testing: ', testscore2)\n",
    "print('score difference: ', trainscore2-testscore2, '\\n\\n\\n')\n",
    "\n",
    "imprtestscore=testscore2-testscore1\n",
    "imprtrainscore=trainscore2-trainscore1\n",
    "\n",
    "\n",
    "print('===================================================')\n",
    "print('Difference between training score with and and without MN features:', imprtrainscore)\n",
    "print('Difference between testing score with and and without MN features:', imprtestscore)\n",
    "print('===================================================', '\\n\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('N:', rf.feature_importances_[0])\n",
    "print('Z:', rf.feature_importances_[1],     '\\n')\n",
    "\n",
    "print('N+Z:', rf.feature_importances_[2])\n",
    "print('N-Z:', rf.feature_importances_[3],   '\\n')\n",
    "\n",
    "print('20-N:', rf.feature_importances_[4])\n",
    "print('20-Z:', rf.feature_importances_[5],  '\\n')\n",
    "\n",
    "print('28-N:', rf.feature_importances_[6])\n",
    "print('28-Z:', rf.feature_importances_[7],  '\\n')\n",
    "\n",
    "print('50-N:', rf.feature_importances_[8])\n",
    "print('50-Z:', rf.feature_importances_[9],  '\\n')\n",
    "\n",
    "print('80-N:', rf.feature_importances_[10])\n",
    "print('80-Z:', rf.feature_importances_[11], '\\n')\n",
    "\n",
    "print('126-N:', rf.feature_importances_[12])\n",
    "print('126-Z:', rf.feature_importances_[13],'\\n')\n",
    "\n",
    "rf.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Have to refit rf with all of X and y \n",
    "#Unlike with scaling\n",
    "\n",
    "pred_all = rf.predict(X) \n",
    "fig=plt.figure(figsize=(18, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "sc = plt.scatter(np.transpose(X)[0],np.transpose(X)[1],c=pred_all,cmap='PiYG',vmin=-ext,vmax=ext,s=10)\n",
    "plt.colorbar(sc)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "err_all=y-pred_all\n",
    "ext1 = np.int(np.ceil(max(-np.min(err_all),np.max(err_all))))\n",
    "fig=plt.figure(figsize=(18, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "sc = plt.scatter(np.transpose(X)[0],np.transpose(X)[1],c=err_all,cmap='PiYG',vmin=-ext1,vmax=ext1,s=10)\n",
    "plt.colorbar(sc)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(N+Z,y,'o',markersize=3,label='Original')\n",
    "plt.plot(np.transpose(X)[0]+np.transpose(X)[1],pred_all,'o',markersize=3,label='Trained')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.transpose(X)[0]+np.transpose(X)[1],err_all,'o',markersize=1,label='Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating RF parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.transpose(np.stack((N,Z)))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train) # This sets the shifting and scaling so the training features have mean zero and variance 1\n",
    "\n",
    "Xs_train = scaler.transform(X_train) # Scaling the training features\n",
    "\n",
    "Xs_test = scaler.transform(X_test) #Using the SAME scaling on the test features in order to get the correct score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "#search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                              n_iter = 100, scoring='neg_mean_absolute_error', \n",
    "                              cv = 3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(Xs_train, y_train)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have to refit rf with all of X and y \n",
    "#Unlike with scaling\n",
    "print(rf_random.score(Xs_train, y_train))\n",
    "Xs = scaler.transform(X)\n",
    "pred_all = rf_random.predict(Xs) \n",
    "fig=plt.figure(figsize=(18, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "sc = plt.scatter(np.transpose(X)[0],np.transpose(X)[1],c=pred_all,cmap='PiYG',vmin=-ext,vmax=ext,s=10)\n",
    "plt.colorbar(sc)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "err_all=y-pred_all\n",
    "ext1 = np.int(np.ceil(max(-np.min(err_all),np.max(err_all))))\n",
    "fig=plt.figure(figsize=(18, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "sc = plt.scatter(np.transpose(X)[0],np.transpose(X)[1],c=err_all,cmap='PiYG',vmin=-ext1,vmax=ext1,s=10)\n",
    "plt.colorbar(sc)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(N+Z,y,'o',markersize=3,label='Original')\n",
    "plt.plot(np.transpose(X)[0]+np.transpose(X)[1],pred_all,'o',markersize=3,label='Trained')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.transpose(X)[0]+np.transpose(X)[1],err_all,'o',markersize=1,label='Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=rf_random.predict(Xs_train)\n",
    "errors = predictions-y_train\n",
    "print('Without Magic Numbers as Features')\n",
    "print('Mean Error for train data:', round(np.mean(errors), 5), )\n",
    "print('Median Error for train data:', round(np.median(errors), 5),'\\n' )\n",
    "Etrain1=np.mean(errors)\n",
    "Emedtrain1=np.median(errors)\n",
    "\n",
    "predictions=rf_random.predict(Xs_test)\n",
    "# Calculate the absolute errors\n",
    "errors = predictions-y_test\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Error for test data:', round(np.mean(errors), 5), )\n",
    "print('Median Error for test data:', round(np.median(errors), 5), '\\n\\n' )\n",
    "\n",
    "Etest1=np.mean(errors)\n",
    "Emedtest1=np.median(errors)\n",
    "\n",
    "\n",
    "#the coefficient of determination R^2 of the prediction\n",
    "# The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum()\n",
    "#and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum().     \n",
    "trainscore1=rf_random.score(Xs_train, y_train)\n",
    "testscore1=rf_random.score(Xs_test, y_test)\n",
    "\n",
    "print('The coefficient of determination for training: ', trainscore1)\n",
    "print('The coefficient of determination for testing: ', testscore1)\n",
    "print('score difference: ', trainscore1-testscore1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "#search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                              n_iter = 100, scoring='neg_mean_absolute_error', \n",
    "                              cv = 6, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(Xs_train, y_train)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have to refit rf with all of X and y \n",
    "#Unlike with scaling\n",
    "print(rf_random.score(Xs_train, y_train))\n",
    "Xs = scaler.transform(X)\n",
    "pred_all = rf_random.predict(Xs) \n",
    "fig=plt.figure(figsize=(18, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "sc = plt.scatter(np.transpose(X)[0],np.transpose(X)[1],c=pred_all,cmap='PiYG',vmin=-ext,vmax=ext,s=10)\n",
    "plt.colorbar(sc)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "err_all=y-pred_all\n",
    "ext1 = np.int(np.ceil(max(-np.min(err_all),np.max(err_all))))\n",
    "fig=plt.figure(figsize=(18, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "sc = plt.scatter(np.transpose(X)[0],np.transpose(X)[1],c=err_all,cmap='PiYG',vmin=-ext1,vmax=ext1,s=10)\n",
    "plt.colorbar(sc)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(N+Z,y,'o',markersize=3,label='Original')\n",
    "plt.plot(np.transpose(X)[0]+np.transpose(X)[1],pred_all,'o',markersize=3,label='Trained')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.transpose(X)[0]+np.transpose(X)[1],err_all,'o',markersize=1,label='Error')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=rf_random.predict(Xs_train)\n",
    "errors = predictions-y_train\n",
    "print('Without Magic Numbers as Features')\n",
    "print('Mean Error for train data:', round(np.mean(errors), 5), )\n",
    "print('Median Error for train data:', round(np.median(errors), 5),'\\n' )\n",
    "Etrain1=np.mean(errors)\n",
    "Emedtrain1=np.median(errors)\n",
    "\n",
    "predictions=rf_random.predict(Xs_test)\n",
    "# Calculate the absolute errors\n",
    "errors = predictions-y_test\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Error for test data:', round(np.mean(errors), 5), )\n",
    "print('Median Error for test data:', round(np.median(errors), 5), '\\n\\n' )\n",
    "\n",
    "Etest1=np.mean(errors)\n",
    "Emedtest1=np.median(errors)\n",
    "\n",
    "\n",
    "#the coefficient of determination R^2 of the prediction\n",
    "# The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum()\n",
    "#and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum().     \n",
    "trainscore1=rf_random.score(Xs_train, y_train)\n",
    "testscore1=rf_random.score(Xs_test, y_test)\n",
    "\n",
    "print('The coefficient of determination for training: ', trainscore1)\n",
    "print('The coefficient of determination for testing: ', testscore1)\n",
    "print('score difference: ', trainscore1-testscore1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
