{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split different ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing essentials\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Innitial look at personal data \n",
    "#difference between experimental binding energies and Liquid Drop Model Binding Energies\n",
    "#The Random Forrest is being trained to predict this difference to 'fix' the liquid drop model \n",
    "\n",
    "N = np.genfromtxt('expthediff.dat',usecols=0) #Number of neutrons\n",
    "Z = np.genfromtxt('expthediff.dat',usecols=1) #Number of protons\n",
    "A = N+Z # Total number of Nucleons\n",
    "# Difference between the experimental binding energy and the Liquid drop model\n",
    "y = np.genfromtxt('expthediff.dat',usecols=2)\n",
    "X = np.transpose(np.stack((N,Z)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Z,y,'o',markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(N,y,'o',markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(A,y,'o',markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = np.int(np.ceil(max(-np.min(y),np.max(y))))\n",
    "fig=plt.figure(figsize=(18, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "sc = plt.scatter(N,Z,c=y,cmap='PiYG',vmin=-ext,vmax=ext,s=10)\n",
    "plt.colorbar(sc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model \n",
    "rf = RandomForestRegressor(n_estimators=1000) #, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_train=[] #ratios\n",
    "nl_test =[]\n",
    "\n",
    "x_tr    =[] #actual \n",
    "x_te    =[]\n",
    "\n",
    "pred_tr =[] #predicted\n",
    "pred_te =[]\n",
    "\n",
    "err_tr  =[] #error\n",
    "err_te  =[]\n",
    "\n",
    "sco_tr  =[] #score\n",
    "sco_te  =[]\n",
    "\n",
    "nerr_tr =[] #mean of error\n",
    "nerr_te =[]\n",
    "\n",
    "sderr_tr=[] #standard Deviation of error\n",
    "sderr_te=[]\n",
    "\n",
    "derr_tr =[] #median of error\n",
    "derr_te =[]\n",
    "\n",
    "#loop to see how different train/test ratios effects bias and variance going from test data set of 5% to 95%\n",
    "for n in range(5, 96, 5):\n",
    "    \n",
    "    #Splitting data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =n/100, random_state=42 )\n",
    "    \n",
    "    #fitting the rf to the training values\n",
    "    rf.fit(X_train, y_train);\n",
    "    \n",
    "    #appending the ratios to the ratio lists\n",
    "    nl_test.append(n)\n",
    "    nl_train.append(100-n)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #appending the ACTUAL values into a list\n",
    "    x_tr.append(X_train)\n",
    "    x_te.append(X_test )\n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    pred_train= rf.predict(X_train)\n",
    "    pred_test = rf.predict(X_test )\n",
    "    \n",
    "    #appending the PREDICTED values of rf into a list\n",
    "    pred_tr.append(pred_train)\n",
    "    pred_te.append(pred_test)\n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    #all error values\n",
    "    err_train = y_train-pred_train\n",
    "    err_test  = y_test- pred_test \n",
    "    \n",
    "    #appending the ERROR values to list\n",
    "    err_tr.append(err_train)\n",
    "    err_te.append(err_test)\n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    #appending the SCORES to the scores lists\n",
    "    sco_tr.append(rf.score(X_train, y_train))\n",
    "    sco_te.append(rf.score(X_test,  y_test ))\n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    #appending the MEAN of the error vaues\n",
    "    nerr_tr.append(np.mean(err_train))\n",
    "    nerr_te.append(np.mean(err_test ))\n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    #appending the STANDARD DEVIATION of the error values\n",
    "    sderr_tr.append(np.std(err_train))\n",
    "    sderr_te.append(np.std(err_test ))\n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    #appending the MEDIAN of the error values\n",
    "    derr_tr.append(np.median(err_train))\n",
    "    derr_te.append(np.median(err_test ))\n",
    "    \n",
    "    \n",
    "    #Printing all the values:\n",
    "    \n",
    "    #ratios\n",
    "    print('train size: ', 100-n, '%')\n",
    "    print('test size:  ', n, '%')\n",
    "    \n",
    "    #scores\n",
    "    print('train score: ', round(rf.score(X_train, y_train),5))\n",
    "    print('test  score: ', round(rf.score(X_test,  y_test ),5))\n",
    "    \n",
    "    #mean error\n",
    "    print('mean error of train:', round(np.mean(err_train),5))\n",
    "    print('mean error of test: ', round(np.mean(err_test),5))\n",
    "    \n",
    "    \n",
    "    #standard Deviatin of error\n",
    "    print('Standard Deviation error of train:', round(np.std(err_train),5))\n",
    "    print('Standard Deviation of test: ', round(np.std(err_test),5))\n",
    "    \n",
    "    #median error\n",
    "    print('median error of train:', round(np.median(err_train),5))\n",
    "    print('median error of test: ', round(np.median(err_test),5))\n",
    "    \n",
    "    \n",
    "    #printing histogram of train\n",
    "    num_bins = 80\n",
    "    n, bins, patches = plt.hist([err_train, err_test], num_bins, alpha=0.5)\n",
    "    #y = mlab.normpdf(bins, np.mean(err_train), np.std(err_train))\n",
    "    #plt.plot(bins, y, 'r--')\n",
    "    plt.ylabel('training error')\n",
    "    plt.xlabel('bins')  \n",
    "    plt.show()\n",
    "    \n",
    "    #printing histogram of train\n",
    "    num_bins = 80\n",
    "    n, bins, patches = plt.hist(err_train , num_bins, facecolor='blue', alpha=0.5)\n",
    "    #y = mlab.normpdf(bins, np.mean(err_test), np.std(err_test))\n",
    "    #plt.plot(bins, y, 'r--')\n",
    "    plt.ylabel('testing error')\n",
    "    plt.xlabel('bins')\n",
    "    plt.show()\n",
    "    \n",
    "    #printing histogram of test\n",
    "    num_bins = 80\n",
    "    n, bins, patches = plt.hist(err_test , num_bins, facecolor='blue', alpha=0.5)\n",
    "    #y = mlab.normpdf(bins, np.mean(err_test), np.std(err_test))\n",
    "    #plt.plot(bins, y, 'r--')\n",
    "    plt.ylabel('testing error')\n",
    "    plt.xlabel('bins')\n",
    "    plt.show()\n",
    "    \n",
    "  \n",
    "    #printing error of train and test\n",
    "    plt.plot(np.transpose(X_train)[0]+np.transpose(X_train)[1], err_train, 'o',markersize=1,label='train Error')\n",
    "    plt.plot(np.transpose(X_test )[0]+np.transpose(X_test )[1], err_test , 'o',markersize=1,label='test  Error')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Error')\n",
    "    plt.xlabel('A')\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arranging data\n",
    "actual    =np.transpose(np.stack((nl_train, nl_test, x_tr, x_te)))\n",
    "Predicted =np.transpose(np.stack((nl_train, nl_test, pred_tr, pred_te)))\n",
    "\n",
    "Error     = np.transpose(np.stack((nl_train, nl_test, err_tr, err_te)))\n",
    "\n",
    "\n",
    "Mean      = np.transpose(np.stack((nl_train, nl_test, nerr_tr, nerr_te)))\n",
    "Stdev     = np.transpose(np.stack((nl_train, nl_test, sderr_tr, sderr_te)))\n",
    "\n",
    "                                 \n",
    "Score     = np.transpose(np.stack((nl_train, nl_test, sco_tr , sco_te)))\n",
    "Median    = np.transpose(np.stack((nl_train, nl_test, derr_tr, derr_te)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "everything=np.transpose(np.stack((nl_train,\n",
    "                                  nl_test,\n",
    "                                  x_tr,\n",
    "                                  x_te,\n",
    "                                  pred_tr,\n",
    "                                  pred_te,\n",
    "                                  err_tr,\n",
    "                                  err_te,\n",
    "                                  nerr_tr, \n",
    "                                  nerr_te,\n",
    "                                  sderr_tr,\n",
    "                                  sderr_te,\n",
    "                                  sco_tr, \n",
    "                                  sco_te,\n",
    "                                  derr_tr, \n",
    "                                  derr_te, \n",
    "                                   )))\n",
    "\n",
    "\"\"\"\n",
    "plt.plot(np.transpose(Score)[0],np.transpose(Score)[2],'o',markersize=3,label='training  score')\n",
    "plt.xlabel('% portion Training')\n",
    "plt.ylabel('R^2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.transpose(Score)[1],np.transpose(Score)[3],'o',markersize=3,label='testing  score')\n",
    "plt.xlabel('% portion Testing')\n",
    "plt.ylabel('R^2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "                                 \n",
    "plt.plot(np.transpose(Score)[0],np.transpose(Score)[3],'o',markersize=3,label='test  score')\n",
    "plt.plot(np.transpose(Score)[0],np.transpose(Score)[2],'o',markersize=3,label='train score')\n",
    "plt.xlabel('% portion Training')\n",
    "plt.ylabel('R^2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"                                 \n",
    "plt.plot(np.transpose(Score)[1],np.transpose(Score)[3],'o',markersize=3,label='test  score')\n",
    "plt.plot(np.transpose(Score)[1],np.transpose(Score)[2],'o',markersize=3,label='train score')\n",
    "plt.xlabel('% portion Testing')\n",
    "plt.ylabel('R^2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plt.plot(np.transpose(Mean)[0],np.transpose(Mean)[2],'o',markersize=3,label='training  Mean error')\n",
    "plt.xlabel('% portion Training')\n",
    "plt.ylabel('Mean error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(np.transpose(Mean)[1],np.transpose(Mean)[3],'o',markersize=3,label='testing  Mean error')\n",
    "plt.xlabel('% portion Testing')\n",
    "plt.ylabel('Mean error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "plt.plot(np.transpose(Mean)[0],np.transpose(Mean)[3],'o',markersize=3,label='test  Mean error')\n",
    "plt.plot(np.transpose(Mean)[0],np.transpose(Mean)[2],'o',markersize=3,label='train Mean error')\n",
    "plt.xlabel('% portion Training')\n",
    "plt.ylabel('absolute Mean error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.transpose(Mean)[0],abs(np.transpose(Mean)[3]),'o',markersize=3,label='abs test  Mean error')\n",
    "plt.plot(np.transpose(Mean)[0],abs(np.transpose(Mean)[2]),'o',markersize=3,label='abs train Mean error')\n",
    "plt.xlabel('% portion Training')\n",
    "plt.ylabel('absolute Mean error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.transpose(Stdev)[0],np.transpose(Stdev)[3],'o',markersize=3,label='test  STD error')\n",
    "plt.plot(np.transpose(Stdev)[0],np.transpose(Stdev)[2],'o',markersize=3,label='train STD error')\n",
    "plt.xlabel('% portion Training')\n",
    "plt.ylabel('Standard Deviation of error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(abs(np.transpose(Mean)[3]))\n",
    "\n",
    "print(abs(np.transpose(Mean)[2]))\n",
    "\"\"\"\n",
    "plt.plot(np.transpose(Mean)[1],np.transpose(Mean)[3],'o',markersize=3,label='test  Mean error')\n",
    "plt.plot(np.transpose(Mean)[1],np.transpose(Mean)[2],'o',markersize=3,label='train Mean error')\n",
    "plt.xlabel('% portion Testing')\n",
    "plt.ylabel('Mean error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plt.plot(np.transpose(Median)[0],np.transpose(Median)[2],'o',markersize=3,label='training  Median error')\n",
    "plt.xlabel('% portion Training')\n",
    "plt.ylabel('Median error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.transpose(Median)[1],np.transpose(Median)[3],'o',markersize=3,label='testing  Median error')\n",
    "plt.xlabel('% portion Testing')\n",
    "plt.ylabel('Median error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "plt.plot(np.transpose(Median)[0],abs(np.transpose(Median)[3]),'o',markersize=3,label='test  Median error')\n",
    "plt.plot(np.transpose(Median)[0],abs(np.transpose(Median)[2]),'o',markersize=3,label='train Median error')\n",
    "plt.xlabel('% portion Training')\n",
    "plt.ylabel('Median error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(np.transpose(Median)[0],np.transpose(Median)[3],'o',markersize=3,label='test  Median error')\n",
    "plt.plot(np.transpose(Median)[0],np.transpose(Median)[2],'o',markersize=3,label='train Median error')\n",
    "plt.xlabel('% portion Training')\n",
    "plt.ylabel('Median error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "plt.plot(np.transpose(Median)[1],np.transpose(Median)[3],'o',markersize=3,label='test  Median error')\n",
    "plt.plot(np.transpose(Median)[1],np.transpose(Median)[2],'o',markersize=3,label='train Median error')\n",
    "plt.xlabel('% portion Testing')\n",
    "plt.ylabel('Median error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score plot\n",
    "plt.plot(np.transpose(Score)[0],np.transpose(Score)[3],'o',markersize=3,label='test  score')\n",
    "plt.plot(np.transpose(Score)[0],np.transpose(Score)[2],'o',markersize=3,label='train score')\n",
    "plt.xlabel('% portion Training')\n",
    "plt.ylabel('R^2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#mean plot\n",
    "plt.plot(abs(np.transpose(Mean)[0]),abs(np.transpose(Mean)[3]),'o',markersize=3,label='test  Mean error')\n",
    "plt.plot(abs(np.transpose(Mean)[0]),abs(np.transpose(Mean)[2]),'o',markersize=3,label='train Mean error')\n",
    "plt.xlabel('% portion Training')\n",
    "plt.ylabel('Mean error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Standard Deviation Plot\n",
    "plt.plot(np.transpose(Stdev)[0],np.transpose(Stdev)[3],'o',markersize=3,label='test  STD error')\n",
    "plt.plot(np.transpose(Stdev)[0],np.transpose(Stdev)[2],'o',markersize=3,label='train STD error')\n",
    "plt.xlabel('% portion Training')\n",
    "plt.ylabel('Standard Deviation of error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Median error plot\n",
    "plt.plot(abs(np.transpose(Median)[0]),abs(np.transpose(Median)[3]),'o',markersize=3,label='test  Median error')\n",
    "plt.plot(abs(np.transpose(Median)[0]),abs(np.transpose(Median)[2]),'o',markersize=3,label='train Median error')\n",
    "plt.xlabel('% portion Training')\n",
    "plt.ylabel('Median error')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ";"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
